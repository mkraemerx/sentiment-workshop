{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data, datasets\n",
    "import torchtext\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from TwitterPipeline import TwitterPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 762\n",
    "IN_FILE = 'germeval2018.try.txt'\n",
    "#IN_FILE = 'germeval2018.training.txt'\n",
    "IN_FILE_TEST = 'germeval2018.test.txt'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext\n",
    "Torchtext is a add-on to pytorch that brings data handlers and other tools for training of language data.\n",
    "\n",
    "### define torchtext.Field instances\n",
    "\n",
    "Fields are explained in the [torchtext docs](https://torchtext.readthedocs.io/en/latest/data.html#field) and shown at work in a [blog post from Allen Nie](http://anie.me/On-Torchtext/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Fields\n",
    "# HINT: don't specify a tokenizer here\n",
    "\n",
    "# assign single fields to map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy\n",
    "A tool from Berlin-based company Explosion AI that offered different language models right from the start. Initially used just as tokenizer, it has since version 2 one the best lemmatizer and POS-taggers for German.\n",
    "\n",
    "[Usage](https://spacy.io/usage/)\n",
    "\n",
    "[Full Documentation](https://spacy.io/api/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spacy pipeline\n",
    "# HINT: a simple one - maybe even without setting the model to use - is easier\n",
    "\n",
    "# pre-process training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of data\n",
    "We need to have 3 separate chunks of data: train, validation and test data\n",
    "\n",
    "Torchtext has methods to help us with that. See [data.Dataset.split()](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the splitting with torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train len {len(trn_ds.examples)}')\n",
    "print(f'val len {len(val_ds.examples)}')\n",
    "print(f'test len {len(tst_ds.examples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "# validation + test data should by no means influence the model, so build the vocab just on trn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'text vocab size {len(f_text.vocab)}')\n",
    "print(f'lemma vocab size {len(f_lemma.vocab)}')\n",
    "print(f'label vocab size {len(f_label.vocab)}')[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator for Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training iterators\n",
    "trn_iter, val_iter, tst_iter = data.BucketIterator.splits((trn_ds, val_ds, tst_ds),\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          device=-1,\n",
    "                                                          sort_key=lambda t: len(\n",
    "                                                              t.text),\n",
    "                                                          sort_within_batch=False,\n",
    "                                                          repeat=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_dim, emb_dim=100, hidden_dim=200):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x type is Tensor[sentence len, batch size]. Internally pytorch does not use 1-hot\n",
    "        \n",
    "        # result should be Tensor[batch size]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric to show model status and progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    return accuracy per batch as ratio of correct/all\n",
    "    \"\"\"\n",
    "\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    # convert into float for division\n",
    "    pred_is_correct = (rounded_preds == y).float()\n",
    "    acc = pred_is_correct.sum()/len(pred_is_correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training function (single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, metric):\n",
    "    epoch_loss = 0\n",
    "    epoch_meter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(batch.text).squeeze(1)\n",
    "        loss = criterion(y_hat, batch.label)\n",
    "        meter = metric(y_hat, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_meter += meter.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_meter / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation (single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, metric):\n",
    "    epoch_loss = 0\n",
    "    epoch_meter = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "            y_hat = model(batch.text).squeeze(1)\n",
    "            loss = criterion(y_hat, batch.label)\n",
    "            meter = metric(y_hat, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_meter += meter.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_meter / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 100\n",
    "HID_SIZE = 200\n",
    "NUM_LIN = 3\n",
    "NUM_EPOCH = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# RNN variant SETUP\n",
    "model = SimpleRNN(len(f_text.vocab), EMB_SIZE, HID_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    train_loss, train_acc = train(\n",
    "        model, trn_iter, optimizer, criterion, binary_accuracy)\n",
    "    valid_loss, valid_acc = evaluate(\n",
    "        model, val_iter, criterion, binary_accuracy)\n",
    "\n",
    "    print(f'EPOCH: {epoch:02} - TRN_LOSS: {train_loss:.3f} - TRN_ACC: {train_acc*100:.2f}% - VAL_LOSS: {valid_loss:.3f} - VAL_ACC: {valid_acc*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, tst_iter, criterion, binary_accuracy)\n",
    "print(f'TEST_LOSS: {test_loss:.3f}, TEST_ACC: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
